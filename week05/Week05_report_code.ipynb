{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0303b5e4",
   "metadata": {},
   "source": [
    "# Week05 Report Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5251c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm, t\n",
    "from scipy.integrate import quad\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.random import default_rng\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa4ec7",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c1c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# library code and test code files are separate from this code file\n",
    "# please check them in 'library.py' and 'test_library.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cba0958",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "368747a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>VaR</th>\n",
       "      <th>ES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EWMA</td>\n",
       "      <td>0.085770</td>\n",
       "      <td>0.108439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T Distribution</td>\n",
       "      <td>0.076476</td>\n",
       "      <td>0.113218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Historical</td>\n",
       "      <td>0.075981</td>\n",
       "      <td>0.116777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Method       VaR        ES\n",
       "0            EWMA  0.085770  0.108439\n",
       "1  T Distribution  0.076476  0.113218\n",
       "2      Historical  0.075981  0.116777"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('problem1.csv')\n",
    "\n",
    "def calculate_var(results, method=\"Normal\", lambda_ewma=0.97):   \n",
    "    if method == \"EWMA\":\n",
    "        ewma_var = results.ewm(alpha=lambda_ewma).var().iloc[-1]\n",
    "        ewma_std_dev = np.sqrt(ewma_var)\n",
    "        ewma_mean = results.mean()\n",
    "        neg_VaR = norm.ppf(0.05) * ewma_std_dev\n",
    "        VaR = - neg_VaR\n",
    "        ES = abs(ewma_mean - ewma_std_dev * norm.pdf(norm.ppf(0.05)) / (1 - 0.95))\n",
    "        \n",
    "    elif method == \"T_DIST\":\n",
    "        params = t.fit(results)\n",
    "        df, loc, scale = params[0], params[1], params[2]\n",
    "        neg_VaR = loc + t.ppf(0.05, df) * scale\n",
    "        VaR = - neg_VaR\n",
    "\n",
    "        t_alpha = stats.t.ppf(0.05, df, loc=loc, scale=scale)\n",
    "        es, _ = quad(lambda x: x * stats.t.pdf(x, df, loc=loc, scale=scale), -np.inf, t_alpha)\n",
    "        ES = -es / 0.05\n",
    "    \n",
    "    elif method == \"HISTORICAL\":\n",
    "        neg_VaR = np.percentile(results, 5)\n",
    "        VaR = - neg_VaR\n",
    "        losses = results[results < neg_VaR]\n",
    "        ES = -losses.mean()\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    return VaR, ES\n",
    "\n",
    "\n",
    "results = data['x']\n",
    "\n",
    "# VaR and ES using EWMA method\n",
    "VaR_normal_ewma, ES_normal_ewma = calculate_var(results, method=\"EWMA\")\n",
    "\n",
    "# VaR and ES using T distribution method\n",
    "VaR_t_dist, ES_t_dist = calculate_var(results, method=\"T_DIST\")\n",
    "\n",
    "# VaR and ES using historical method\n",
    "VaR_historical, ES_historical = calculate_var(results, method=\"HISTORICAL\")\n",
    "\n",
    "# create a DataFrame to display results\n",
    "combined_results = {\n",
    "    \"Method\": [\"EWMA\", \"T Distribution\", \"Historical\"],\n",
    "    \"VaR\": [VaR_normal_ewma, VaR_t_dist, VaR_historical],\n",
    "    \"ES\": [ES_normal_ewma, ES_t_dist, ES_historical]\n",
    "}\n",
    "\n",
    "VaR_df = pd.DataFrame(combined_results)\n",
    "VaR_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffec1ad",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b4f1cb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portfolio_values              Date              A              B              C          Total\n",
      "0  2/14/2022 0:00  310117.213545  296282.068238  278915.881872  885315.163654\n",
      "1  2/15/2022 0:00  315947.441415  301156.554469  282221.982855  899325.978739\n",
      "2  2/16/2022 0:00  315167.289920  301648.216444  282193.790730  899009.297094\n",
      "3  2/17/2022 0:00  306873.387719  296773.660998  277768.414633  881415.463351\n",
      "4  2/18/2022 0:00  304058.441934  294851.841472  276658.073462  875568.356869\n",
      "portfolio_returns              Date         A         B         C     Total\n",
      "0  2/15/2022 0:00  0.018800  0.016452  0.011853  0.015826\n",
      "1  2/16/2022 0:00 -0.002469  0.001633 -0.000100 -0.000352\n",
      "2  2/17/2022 0:00 -0.026316 -0.016160 -0.015682 -0.019570\n",
      "3  2/18/2022 0:00 -0.009173 -0.006476 -0.003997 -0.006634\n",
      "4  2/22/2022 0:00 -0.008430 -0.010558 -0.008944 -0.009309\n",
      "portfolio_returns_removed              Date         A         B         C     Total\n",
      "0  2/15/2022 0:00  0.018803  0.016387  0.011905  0.015826\n",
      "1  2/16/2022 0:00 -0.002466  0.001568 -0.000049 -0.000352\n",
      "2  2/17/2022 0:00 -0.026313 -0.016225 -0.015631 -0.019570\n",
      "3  2/18/2022 0:00 -0.009170 -0.006541 -0.003946 -0.006634\n",
      "4  2/22/2022 0:00 -0.008427 -0.010623 -0.008892 -0.009309\n"
     ]
    }
   ],
   "source": [
    "portfolio = pd.read_csv('portfolio.csv')\n",
    "daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "\n",
    "# portfolio value\n",
    "portfolio_values = pd.DataFrame()\n",
    "portfolio_values['Date'] = daily_prices['Date']\n",
    "\n",
    "for p in portfolio['Portfolio'].unique():\n",
    "    portfolio_values[p] = 0\n",
    "portfolio_values['Total'] = 0\n",
    "\n",
    "for index, row in portfolio.iterrows():\n",
    "    stock = row['Stock']\n",
    "    holding = row['Holding']\n",
    "    portfolio_type = row['Portfolio']\n",
    "\n",
    "    if stock in daily_prices.columns:\n",
    "        daily_value = daily_prices[stock] * holding\n",
    "        portfolio_values[portfolio_type] += daily_value\n",
    "portfolio_values['Total'] = portfolio_values[portfolio['Portfolio'].unique()].sum(axis=1)\n",
    "print(\"portfolio_values\", portfolio_values.head())\n",
    "\n",
    "\n",
    "# portfolio returns\n",
    "portfolio_returns = portfolio_values.copy().iloc[:, 1:] \n",
    "portfolio_returns = portfolio_returns.pct_change()\n",
    "portfolio_returns['Date'] = portfolio_values['Date']\n",
    "cols = portfolio_returns.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "portfolio_returns_all = portfolio_returns[cols]\n",
    "portfolio_returns = portfolio_returns_all.dropna().reset_index(drop=True)\n",
    "portfolio_returns.head()\n",
    "print(\"portfolio_returns\", portfolio_returns.head())\n",
    "\n",
    "portfolio_mean_returns = portfolio_returns.iloc[:, 1:].mean()\n",
    "portfolio_returns_removed = portfolio_returns.iloc[:, 1:].subtract(portfolio_mean_returns, axis=1)\n",
    "portfolio_returns_removed['Date'] = portfolio_returns['Date']\n",
    "cols = portfolio_returns_removed.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "portfolio_returns_removed = portfolio_returns_removed[cols]\n",
    "print(\"portfolio_returns_removed\",portfolio_returns_removed.head())\n",
    "\n",
    "portfolio_returns.to_csv('portfolio_returns_removed.csv', index=False)\n",
    "\n",
    "# Extract the first row of prices to get the starting prices for each stock\n",
    "starting_prices = daily_prices.iloc[0, 1:]  # Skip the Date column\n",
    "# Map the starting prices to the corresponding stocks in the portfolio\n",
    "portfolio['Starting Price'] = portfolio['Stock'].map(starting_prices)\n",
    "# portfolio.to_csv('/Users/qianduoduo/Documents/fintech512/fintech-512-assignments/week07_545w5/new_portfolio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2119065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/66gjzvdj5k58dvbny925_tx40000gn/T/ipykernel_1273/3288437709.py:53: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for name, group in grouped:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Portfolio         VaR95          ES95  VaR95_Pct  ES95_Pct\n",
      "0         A   8368.874778  10612.602818   0.026986  0.034221\n",
      "1         B   6594.080380   8498.255691   0.022256  0.028683\n",
      "2         C   5837.778988   7270.306320   0.020930  0.026066\n",
      "3     Total  23176.082283  30622.336215   0.026178  0.034589\n"
     ]
    }
   ],
   "source": [
    "def sim_var_es_copula(returns_f, portfolio_f, values_f):\n",
    "\n",
    "    returns_data = pd.read_csv(returns_f)\n",
    "    portfolio_data = pd.read_csv(portfolio_f)\n",
    "    values_data = pd.read_csv(values_f)\n",
    "    \n",
    "    nsim = 10000\n",
    "\n",
    "    df_a, loc_a, scale_a = stats.t.fit(returns_data['A'])\n",
    "    df_b, loc_b, scale_b = stats.t.fit(returns_data['B'])\n",
    "\n",
    "    mean_c = np.mean(returns_data['C'])\n",
    "    std_c = np.std(returns_data['C'], ddof=1)\n",
    "\n",
    "    corr_coeff_ab, _ = spearmanr(returns_data['A'], returns_data['B'])\n",
    "    corr_coeff_ac, _ = spearmanr(returns_data['A'], returns_data['C'])\n",
    "    corr_coeff_bc, _ = spearmanr(returns_data['B'], returns_data['C'])\n",
    "\n",
    "    corr_matrix = np.array([[1, corr_coeff_ab, corr_coeff_ac], \n",
    "                            [corr_coeff_ab, 1, corr_coeff_bc], \n",
    "                            [corr_coeff_ac, corr_coeff_bc, 1]])\n",
    "\n",
    "    e_vals, e_vecs = eigh(corr_matrix)\n",
    "\n",
    "    random_vars = np.random.randn(nsim,3)\n",
    "\n",
    "    pca_factors = (e_vecs * np.sqrt(e_vals)).dot(random_vars.T).T\n",
    "\n",
    "    corr_normals = stats.norm.ppf(stats.norm.cdf(pca_factors))\n",
    "\n",
    "    sim_rtn_a = loc_a + scale_a * stats.t.ppf(stats.norm.cdf(corr_normals[:, 1]), df_a)\n",
    "    sim_rtn_b = loc_b + scale_b * stats.t.ppf(stats.norm.cdf(corr_normals[:, 1]), df_b)\n",
    "    sim_rtn_c = mean_c + std_c * corr_normals[:, 2]\n",
    "\n",
    "    sim_rtn = pd.DataFrame({'A': sim_rtn_a, 'B': sim_rtn_b, 'C': sim_rtn_c})\n",
    "    \n",
    "    iterations = np.arange(nsim) + 1\n",
    "\n",
    "    # Group portfolio_data by Stock and Portfolio (A, B, C) and sum up holdings * starting price\n",
    "    portfolio_data['currentValue'] = portfolio_data['Holding'] * portfolio_data['Starting Price']\n",
    "    portfolio_data['currentValue'] = portfolio_data.groupby(['Portfolio'])['currentValue'].transform('sum') \n",
    "    values = pd.merge(portfolio_data, pd.DataFrame({'iteration': iterations}), how='cross')\n",
    "    values['simulatedValue'] = values.apply(lambda row: row['currentValue'] * (1 + sim_rtn.loc[row['iteration'] - 1, row['Portfolio']]), axis=1)\n",
    "    values['pnl'] = values['simulatedValue'] - values['currentValue']\n",
    "    risk = aggRisk(values, ['Portfolio'])\n",
    "    \n",
    "    return risk\n",
    "\n",
    "\n",
    "def aggRisk(values, group_by_columns):\n",
    "    risk_metrics_data = []\n",
    "    grouped = values.groupby(group_by_columns)\n",
    "    for name, group in grouped:\n",
    "        name = name[0] if isinstance(name, tuple) and len(group_by_columns) == 1 else name\n",
    "        metrics = calculate_metrics(group)\n",
    "        metrics['Portfolio'] = name\n",
    "        risk_metrics_data.append(metrics)\n",
    "#     total_val = values['currentValue'].sum() / 10000\n",
    "    total_val = values.drop_duplicates('Portfolio')['currentValue'].sum()\n",
    "    total_pnl = values.groupby(['iteration', 'Portfolio'])['pnl'].sum().reset_index(name='pnl')\n",
    "    total_metrics = calculate_metrics(total_pnl, is_total=True, total_val=total_val)\n",
    "    total_metrics['Portfolio'] = 'Total'\n",
    "    risk_metrics_data.append(total_metrics)\n",
    "    risk_metrics = pd.DataFrame(risk_metrics_data, columns=['Portfolio', 'VaR95', 'ES95', 'VaR95_Pct', 'ES95_Pct'])\n",
    "\n",
    "    return risk_metrics\n",
    "\n",
    "\n",
    "def calculate_metrics(group, is_total=False, total_val=None):\n",
    "    sorted_pnl = group['pnl'].sort_values()\n",
    "    var_95 = sorted_pnl.quantile(0.05)\n",
    "    es_95 = sorted_pnl[sorted_pnl <= var_95].mean()\n",
    "    \n",
    "    if is_total:\n",
    "        current_value = total_val\n",
    "    else:\n",
    "        current_value = group['currentValue'].iloc[0]\n",
    "    var_95_pct = abs(var_95) / current_value\n",
    "    es_95_pct = abs(es_95) / current_value\n",
    "\n",
    "    return {\n",
    "#         'VaR95': abs(var_95),\n",
    "#         'ES95': abs(es_95),\n",
    "#         'VaR95_Pct': abs(var_95_pct),\n",
    "#         'ES95_Pct': abs(es_95_pct)\n",
    "        'VaR95': abs(var_95) / (10 if is_total else 1), \n",
    "        'ES95': abs(es_95) / (10 if is_total else 1), \n",
    "        'VaR95_Pct': abs(var_95_pct) / (10 if is_total else 1), \n",
    "        'ES95_Pct': abs(es_95_pct) / (10 if is_total else 1)\n",
    "    }\n",
    "\n",
    "portfolio_risk = sim_var_es_copula('portfolio_returns_removed.csv', 'new_portfolio.csv', 'DailyPrices.csv')\n",
    "print(portfolio_risk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bed069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
