{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ab77a7",
   "metadata": {},
   "source": [
    "# Week04_Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c194c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import norm, t\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09f76c",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30323565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical Brownian Motion\n",
      "mean price at time t 100.00186392342633\n",
      "standard deviation of price at time t 0.9967223374418334\n",
      "\n",
      "Arithmetic Return System\n",
      "mean price at time t 100.18639234263283\n",
      "standard deviation of price at time t 99.67223374418334\n",
      "\n",
      "Log Return or Geometric Brownian Motion\n",
      "mean price at time t 164.5837853637429\n",
      "standard deviation of price at time t 212.9412992031013\n"
     ]
    }
   ],
   "source": [
    "n = 100000\n",
    "sigma = 1\n",
    "p_t_1 = 100\n",
    "\n",
    "r_t = np.random.normal(0, sigma, n)\n",
    "\n",
    "# classical brownian motion\n",
    "cl_price_t = p_t_1 + r_t\n",
    "cl_mean = np.mean(cl_price_t)\n",
    "cl_std_dev = np.std(cl_price_t)\n",
    "\n",
    "# arithmetic return system\n",
    "ar_price_t = p_t_1 * (1 + r_t) \n",
    "ar_mean = np.mean(ar_price_t)\n",
    "ar_std_dev = np.std(ar_price_t)\n",
    "\n",
    "# log return or geometric brownian motion\n",
    "log_price_t = p_t_1 * np.exp(r_t) \n",
    "log_mean = np.mean(log_price_t)\n",
    "log_std_dev = np.std(log_price_t)\n",
    "\n",
    "# print simulation results\n",
    "print(\"Classical Brownian Motion\")\n",
    "print(\"mean price at time t\", cl_mean)\n",
    "print(\"standard deviation of price at time t\", cl_std_dev)\n",
    "\n",
    "print(\"\\nArithmetic Return System\")\n",
    "print(\"mean price at time t\", ar_mean)\n",
    "print(\"standard deviation of price at time t\", ar_std_dev)\n",
    "\n",
    "print(\"\\nLog Return or Geometric Brownian Motion\")\n",
    "print(\"mean price at time t\", log_mean)\n",
    "print(\"standard deviation of price at time t\", log_std_dev)\n",
    "\n",
    "# calculation by formula with e\n",
    "result = 100 * math.exp(0.5)\n",
    "# print(result)\n",
    "\n",
    "result1 = 100 * math.sqrt((math.exp(1) - 1) * math.exp(1))\n",
    "# print(result1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa4e44",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e5cd5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    -0.033266\n",
      "2    -0.013890\n",
      "3     0.008882\n",
      "4     0.007625\n",
      "5     0.040962\n",
      "6    -0.003910\n",
      "7    -0.096478\n",
      "8    -0.013628\n",
      "9    -0.015463\n",
      "10   -0.024586\n",
      "Name: META, dtype: float64\n",
      "VaR using normal distribution: -0.054184407435059055\n",
      "VaR using normal distribution with exponentially weighted variance: -0.028695021689623897\n",
      "VaR using T distribution: -0.04313471495037609\n",
      "VaR using a fitted AR(1) model: -0.053730339133240025\n",
      "VaR using historical distribution: -0.03948424995533789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lf/66gjzvdj5k58dvbny925_tx40000gn/T/ipykernel_49394/2620388888.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[var] = p2[:, i]\n",
      "/var/folders/lf/66gjzvdj5k58dvbny925_tx40000gn/T/ipykernel_49394/2620388888.py:42: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  out[var] = p2[:, i]\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file\n",
    "prices = pd.read_csv('DailyPrices.csv')\n",
    "\n",
    "def return_calculate(prices, method=\"DISCRETE\", date_column=\"Date\"):\n",
    "    \n",
    "    if date_column not in prices.columns:\n",
    "        raise ValueError(f\"dateColumn: {dateColumn} not in DataFrame: {list(prices.columns)}\")\n",
    "    \n",
    "    vars = prices.columns\n",
    "    n_vars = len(vars)\n",
    "    n_vars = n_vars - 1\n",
    "    \n",
    "    # remove date column\n",
    "    vars = [col for col in prices.columns if col != date_column]\n",
    "  \n",
    "    p = prices[vars].values\n",
    "    n = p.shape[0]\n",
    "    m = p.shape[1]\n",
    "    \n",
    "    # initialize array\n",
    "    p2 = np.empty((n-1, m))\n",
    "    \n",
    "    # calculate returns\n",
    "    for i in range(n-1):\n",
    "        for j in range(m):\n",
    "            p2[i, j] = p[i+1, j] / p[i, j]\n",
    "    \n",
    "    # returns based on the specified method\n",
    "    if method.upper() == \"DISCRETE\":\n",
    "        p2 = p2 - 1.0\n",
    "    elif method.upper() == \"LOG\":\n",
    "        p2 = np.log(p2)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "    \n",
    "    # extract the date column\n",
    "    dates = prices[date_column].iloc[1:]\n",
    "    out = pd.DataFrame({date_column: dates})\n",
    "    \n",
    "    # returns to the DataFrame\n",
    "    for i, var in enumerate(vars):\n",
    "        out[var] = p2[:, i] \n",
    "    \n",
    "    return out\n",
    "\n",
    "# calculate arithmetic returns\n",
    "returns = return_calculate(prices, method=\"DISCRETE\", date_column=\"Date\")\n",
    "return_mean_meta = returns['META'].mean()\n",
    "return_removed_meta = returns['META'] - return_mean_meta\n",
    "\n",
    "print(return_removed_meta.head(10))\n",
    "# print(return_mean_meta)\n",
    "# print(returns['META'].std())\n",
    "# print(return_removed_meta.mean())\n",
    "# print(return_removed_meta.std())\n",
    "\n",
    "\n",
    "def calculate_var(results, method=\"Normal\", lambda_ewv=0.94):\n",
    "    if method == \"Normal\":\n",
    "        var = norm.ppf(0.05) * np.std(results)\n",
    "        \n",
    "    elif method == \"EWV\":\n",
    "        ewv_var = return_removed_meta.ewm(alpha=lambda_ewv).var().iloc[-1]\n",
    "        ewv_std_dev = np.sqrt(ewv_var)\n",
    "        var = norm.ppf(0.05) * ewv_std_dev\n",
    "        \n",
    "    elif method == \"T_DIST\":\n",
    "        params = t.fit(results)\n",
    "        var = t.ppf(0.05, *params)\n",
    "        \n",
    "    elif method == \"AR1\":\n",
    "        model_arima = ARIMA(return_removed_meta, order=(1, 0, 0))\n",
    "        model_arima_fit = model_arima.fit()\n",
    "\n",
    "        forecast = model_arima_fit.get_forecast(steps=1, alpha=0.05)\n",
    "        var = norm.ppf(0.05, loc=forecast.predicted_mean.values[-1], scale=forecast.se_mean.values[-1])\n",
    "\n",
    "    elif method == \"HISTORICAL\":\n",
    "        var = np.percentile(results, 5)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    return var\n",
    "\n",
    "\n",
    "VaR_normal = calculate_var(return_removed_meta, method=\"Normal\")\n",
    "VaR_normal_ewv = calculate_var(return_removed_meta, method=\"EWV\")\n",
    "VaR_t_distn = calculate_var(return_removed_meta, method=\"T_DIST\")\n",
    "VaR_AR1 = calculate_var(return_removed_meta, method=\"AR1\")\n",
    "VaR_historical = calculate_var(return_removed_meta, method=\"HISTORICAL\")\n",
    "\n",
    "print(\"VaR using normal distribution:\", VaR_normal)\n",
    "print(\"VaR using normal distribution with exponentially weighted variance:\", VaR_normal_ewv )\n",
    "print(\"VaR using T distribution:\", VaR_t_distn)\n",
    "print(\"VaR using a fitted AR(1) model:\", VaR_AR1)\n",
    "print(\"VaR using historical distribution:\", VaR_historical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3aa69",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01ef4883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "portfolio_values          Date              A              B             C         Total\n",
      "0  2022-09-01  864511.243155  524138.141658  1.095803e+06  2.484453e+06\n",
      "1  2022-09-02  855196.252739  519074.251166  1.081036e+06  2.455307e+06\n",
      "2  2022-09-06  854111.899156  517844.336430  1.074900e+06  2.446856e+06\n",
      "3  2022-09-07  868575.869512  527874.300107  1.100873e+06  2.497323e+06\n",
      "4  2022-09-08  875384.565354  532238.524863  1.134243e+06  2.541866e+06\n",
      "portfolio_returns          Date         A         B         C     Total\n",
      "0  2022-09-02 -0.010775 -0.009661 -0.013476 -0.011731\n",
      "1  2022-09-06 -0.001268 -0.002369 -0.005677 -0.003442\n",
      "2  2022-09-07  0.016935  0.019369  0.024163  0.020625\n",
      "3  2022-09-08  0.007839  0.008268  0.030313  0.017837\n",
      "4  2022-09-09  0.014413  0.016863  0.020010  0.017424\n",
      "portfolio_returns_removed          Date         A         B         C     Total\n",
      "0  2022-09-02 -0.011711 -0.010085 -0.014428 -0.012567\n",
      "1  2022-09-06 -0.002204 -0.002793 -0.006629 -0.004278\n",
      "2  2022-09-07  0.015998  0.018945  0.023211  0.019789\n",
      "3  2022-09-08  0.006902  0.007844  0.029361  0.017001\n",
      "4  2022-09-09  0.013476  0.016440  0.019058  0.016588\n",
      "\n",
      "VaR_ewv: \n",
      " A       -0.014031\n",
      "B       -0.013552\n",
      "C       -0.012849\n",
      "Total   -0.012495\n",
      "Name: 264, dtype: float64\n",
      "\n",
      "dollar VaR_ewv based on average portfolio value:\n",
      " A       -13274.616433\n",
      "B        -7555.410422\n",
      "C       -16233.203672\n",
      "Total   -34573.473658\n",
      "dtype: float64\n",
      "\n",
      "dollar VaR_ewv based on the latest portfolio value:\n",
      " A       -15284.381988\n",
      "B        -7786.275435\n",
      "C       -17826.136417\n",
      "Total   -38125.122984\n",
      "dtype: object\n",
      "\n",
      "VaR_normal: \n",
      " A       -0.018660\n",
      "B       -0.020472\n",
      "C       -0.018318\n",
      "Total   -0.018098\n",
      "dtype: float64\n",
      "\n",
      "dollar VaR_normal based on average portfolio value:\n",
      " A       -17654.090247\n",
      "B       -11413.482225\n",
      "C       -23143.422693\n",
      "Total   -50078.164188\n",
      "dtype: float64\n",
      "\n",
      "dollar VaR_normal based on the latest portfolio value:\n",
      " A       -20326.904385\n",
      "B       -11762.235445\n",
      "C       -25414.441809\n",
      "Total    -55222.57287\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read CSV file\n",
    "portfolio = pd.read_csv('Portfolio.csv')\n",
    "# Read CSV file\n",
    "daily_prices = pd.read_csv('DailyPrices.csv')\n",
    "\n",
    "# portfolio value\n",
    "portfolio_values = pd.DataFrame()\n",
    "portfolio_values['Date'] = daily_prices['Date']\n",
    "\n",
    "for p in portfolio['Portfolio'].unique():\n",
    "    portfolio_values[p] = 0\n",
    "portfolio_values['Total'] = 0\n",
    "\n",
    "for index, row in portfolio.iterrows():\n",
    "    stock = row['Stock']\n",
    "    holding = row['Holding']\n",
    "    portfolio_type = row['Portfolio']\n",
    "\n",
    "    if stock in daily_prices.columns:\n",
    "        daily_value = daily_prices[stock] * holding\n",
    "        portfolio_values[portfolio_type] += daily_value\n",
    "portfolio_values['Total'] = portfolio_values[portfolio['Portfolio'].unique()].sum(axis=1)\n",
    "print(\"portfolio_values\", portfolio_values.head())\n",
    "\n",
    "\n",
    "# portfolio returns\n",
    "portfolio_returns = portfolio_values.copy().iloc[:, 1:] \n",
    "portfolio_returns = portfolio_returns.pct_change()\n",
    "portfolio_returns['Date'] = portfolio_values['Date']\n",
    "cols = portfolio_returns.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "portfolio_returns_all = portfolio_returns[cols]\n",
    "portfolio_returns = portfolio_returns_all.dropna().reset_index(drop=True)\n",
    "portfolio_returns.head()\n",
    "print(\"portfolio_returns\", portfolio_returns.head())\n",
    "\n",
    "\n",
    "# portfolio returns exclude mean returns\n",
    "portfolio_mean_returns = portfolio_returns.iloc[:, 1:].mean()\n",
    "portfolio_returns_removed = portfolio_returns.iloc[:, 1:].subtract(portfolio_mean_returns, axis=1)\n",
    "portfolio_returns_removed['Date'] = portfolio_returns['Date']\n",
    "cols = portfolio_returns_removed.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "portfolio_returns_removed = portfolio_returns_removed[cols]\n",
    "print(\"portfolio_returns_removed\",portfolio_returns_removed.head())\n",
    "\n",
    "\n",
    "# calculate emv VaR\n",
    "lambda_ewv = 0.94\n",
    "ewv_var = portfolio_returns_removed.iloc[:, 1:].ewm(alpha=1 - lambda_ewv).var().iloc[-1]\n",
    "ewv_std_dev = np.sqrt(ewv_var)\n",
    "VaR_ewv = norm.ppf(0.05) * ewv_std_dev\n",
    "print(\"\\nVaR_ewv: \\n\",VaR_ewv)\n",
    "# calculate dollar VaR based on average portfolio value\n",
    "average_portfolio_values = portfolio_values.iloc[:, 1:].mean()\n",
    "average_dollar_var = VaR_ewv * average_portfolio_values\n",
    "print(\"\\ndollar VaR_ewv based on average portfolio value:\\n\",average_dollar_var)\n",
    "# calculate dollar VaR based on latest portfolio value\n",
    "latest_portfolio_values = portfolio_values.iloc[-1, 1:]\n",
    "dollar_var_l = VaR_ewv * latest_portfolio_values\n",
    "print(\"\\ndollar VaR_ewv based on the latest portfolio value:\\n\", dollar_var_l)\n",
    "\n",
    "\n",
    "\n",
    "# calculate normal VaR\n",
    "returns_mean = portfolio_returns_removed.iloc[:, 1:].mean()\n",
    "returns_std = portfolio_returns_removed.iloc[:, 1:].std()\n",
    "VaR_normal = norm.ppf(0.05) * returns_std\n",
    "print(\"\\nVaR_normal: \\n\",VaR_normal)\n",
    "# calculate dollar VaR based on average portfolio value\n",
    "average_portfolio_values_n = portfolio_values.iloc[:, 1:].mean()\n",
    "average_dollar_var_n = VaR_normal * average_portfolio_values_n\n",
    "print(\"\\ndollar VaR_normal based on average portfolio value:\\n\", average_dollar_var_n)\n",
    "# calculate dollar VaR based on latest portfolio value\n",
    "latest_portfolio_values_n = portfolio_values.iloc[-1, 1:]\n",
    "dollar_var_l_n = VaR_normal * latest_portfolio_values_n\n",
    "print(\"\\ndollar VaR_normal based on the latest portfolio value:\\n\", dollar_var_l_n)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
